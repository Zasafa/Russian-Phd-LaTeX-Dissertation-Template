\chapter{Метод стохастической оптимизации при решении обратной задачи
  теории Ми} \label{chapt2}

\section{Сравнение методов стохастической оптимизации}
\label{sec:construct-review}

Прогресс в области нанофотоники, как и во многих других разделах
физики, происходит при одновременном развитии теории и эксперимента,
которые оказываются тесно связаны между собой.  Эксперимент определяет
меру правильности теоретических построений и, в то же время, является
источником новых физических эффектов. В последнем случае, определяющей
становится роль теоретического анализа, необходимого для выделения
сути явления из вороха возможных побочных факторов.  Аналогично, при
исследовании оптических свойств наночастиц можно брать результаты
эксперимента и потом проверять, насколько они соотносятся с
существующими моделями. Либо можно вначале находить теоретически
дизайны с новыми физическими свойствами, а уже потом проверять их
экспериментально.  Учитывая высокую стоимость и трудоёмкость
эксперимента в области оптики наночастиц вариант с предварительным
теоретическим анализом проблемы оказывается более рациональным.

Теория Ми позволяет изучать целый ряд физических величин, в число
которых входят, например, сечения рассеяния и поглощения,
распределение электромагнитного поля как внутри, так и вблизи
наночастицы.  Дополнительно в теории Ми есть возможность разделять
вклады связанные с дипольными резонансами, квадрупольными и
мультиполями большего порядка. Такое разнообразие сильно затрудняет
решение обратной задачи, где требуется определить дизайн наночастицы
для достижения заданных характеристик взаимодействия с падающей
волной. Кроме того, заданным параметрам может соответствовать
несколько дизайнов или ни одного.

Попытка решать эту задачу полностью аналитически сразу приводит к
необходимости выбора тех характеристик взаимодействия поля с частицей,
чьи значения будут определять наиболее подходящий дизайн. Другими
словами, необходимо будет решать обратную задачу отдельно для сечения
рассеяния, отдельно для коэффициента усиления поля и так далее, а это
многократно увеличивает объём необходимых работ. Более того,
использование только аналитического подхода заведомо оказывается
неприменимым при учёте экспериментально измеренных дисперсионных
зависимостей материальных параметров. Например, когда требуется
определить дизайн частицы из заданных металлов для получения нужных
рабочих характеристик в какой-то полосе частот и дополнительно
найти оптимальную длину волны внутри выбранного диапазона.  В
результате, наиболее универсальным представляется численное решение,
когда компьютерная программа выбирает параметры дизайна наночастицы
максимально приближенные к оптимальным.

Для численного решения обратную задачу теории Ми можно
переформулировать в общем виде. Будем рассматривать расчёт по теории
Ми в виде некой сложной функции, которая в контексте численного
решения называется целевой функцией $f(\mathbf{x})$, в англоязычной
литературе используются термины objective function или fitness
function.  Целевая функция получает вектор значений для входных
параметров, который в нашем случае является списком из показателей
преломления и толщин каждого слоя. Результат вычисления целевой
функции получается в виде скаляра, который при решении задачи Ми может
быть как значением физической величины, получаемой из расчёта, так и
некой искусственной композицией, характеризующей отклик системы в
целом, например, отношение сечений рассеяния и поглощения. Тогда
обратную задачу можно сформулировать, как поиск такого вектора входных
параметров для целевой функции, который позволял бы получить на выходе
значение, равное заранее заданной величине или наиболее приближенное к
ней. Таким образом, на этапе формулирования общего вида задачи
снимается вопрос о существовании её решения: если нет точного ответа,
то будет получено приблизительное значение. Этого может оказаться
достаточно для обеспечения потребностей широкого круга практических
задач.

При такой постановке вопроса становится возможным использовать
различные методы численной оптимизации, которые позволяют находить
положение экстремума у произвольной функции. Поиск вектора входных
параметров $\mathbf{x_t}$, который позволяет получить целевое значение
$y_t=f(\mathbf{x_t})$, сводится к поиску минимума для новой целевой
функции $\left|f(\mathbf{x})-y_t\right|$.

При выборе конкретного метода оптимизации возникает сложность,
обусловленная их огромным количеством и большим числом
модификаций каждого из них. При выборе метода применительно к задаче
Ми были использованы следующие предпосылки:
\begin{itemize}
\item \label{ref:why-jade} Несмотря на то, что решение Ми является аналитическим и
  выражается разложением в ряд по сферическим векторным
  гармоникам, одновременное нахождение производных для зависимости от
  радиуса и материального параметра оказывается громоздким даже в
  случае однородной сферы. Это тем более верно для случая
  произвольного числа сферических слоёв, где решение получается в виде
  рекуррентного соотношения.  Таким образом, метод оптимизации не
  должен требовать для своей работы нахождения значений производных
  оптимизируемой функции, что особенно актуально в случае, когда
  одновременно оптимизируются и толщина, и показатель преломления
  каждого слоя.
\item Решение образовано осциллирующими функциями и, как следствие,
  будет содержать большое количество локальных экстремумов. Поэтому
  алгоритмы оптимизации, требующие особого отношения к подобным
  случаям, оказываются заведомо менее производительными.
\item Параметры оптимизации и оптимизируемая величина являются
  вещественными числами.
\end{itemize}

Всё вместе это приводит к необходимости исключить из рассмотрения
такие популярные алгоритмы, как метод наискорейшего спуска (требующий
вычисления градиента), симплекс--метод Нелдера--Мида (есть сложность с
локальными экстремумами) и аналогичные им. В результате, приходится
ограничить выбор стохастическими подходами, среди которых наиболее
распространёнными являются генетические
алгоритмы~\cite{Goldberg-GA-1989}, методы  роя
частиц~\cite{Kennedy-PSO-1995} и дифференциальной
эволюции~\cite{Storn-DE-first-1997}.  Все эти алгоритмы используют
метод <<проб и ошибок>>.  Несколько пробных решений, называемых
индивидами, генерируются случайным образом и многократно (итеративно)
улучшаются в надежде найти некое удовлетворительное решение. Качество
решения оценивается целевой функцией, которая должна быть
сформулирована в оптимизируемой задаче.  Полная группа индивидов
образует популяцию.  Состояние популяции на конкретном шаге итерации
называется поколением.  Переход между поколениями осуществляется в
соответствии с рядом относительно простых правил, которые составляют
сущность определённого алгоритма.

Генетические алгоритмы обычно рассматривают вещественные числа в виде
набора битов.  В отличие от них, методы роя частиц и дифференциальной
эволюции могут работать в непрерывном пространстве вещественных
входных параметров естественным образом (используя возможность
сложения и вычитания векторов пробных решений), что делает их гораздо
более удобными для физических и инженерных задач.  Производительность
этих алгоритмов зависит от правильного выбора значений некоторых
внутренних параметров.  Использование адаптивных версий алгоритмов
упрощает задачу оптимизации: для них значения внутренних параметров
настраиваются автоматически при переходе между поколениями. Как
правило, адаптивным алгоритмам нужно гораздо меньше (более чем на
порядок) итераций, чем неадаптивным, чтобы добиться того же результата
оптимизации. Такое поведение тесно связано с так называемой теоремой
<<об отсутствии бесплатных обедов>>~\cite{Wolpert-NFL-1997} (No free
lunch theorem). Она была доказана в достаточно общем виде и,
упрощённо, утверждает, что если в наборе методов оптимизации какой-то
один метод оказался лучше для выбранного множества целевых функций, то
обязательно существует другое множество целевых функций, где этот
метод перестанет быть лучшим. В адаптивном случае выбор наилучшего
алгоритма происходит прямо во время оптимизации для текущей фазы
поиска минимума у конкретной тестовой функции, что и обуславливает
значительное необходимого числа итераций. Хотя, разумеется, можно
сконструировать такие тестовые функции, которые не будут требовать
адаптации алгоритма, и для них адаптивные методы могут несколько
проиграть неадаптивным (вследствие наличия дополнительных вычислений,
необходимых для адаптации).

Сравнение~\cite{Gong-compare-EA-2014,Kang-compare-EA-RABC-2011}
адаптивного алгоритма дифференциальной эволюции
JADE~\cite{Jingqiao-JADE-2009} с адаптивной оптимизацией методом роя
частиц~\cite{Zhan-APSO-2008} и многими другими методами показало
превосходство JADE или результат сопоставимый с лучшими из числа
протестированных методов оптимизации для большинства стандартных
тестов~\cite{Schwefel-1981,Rosenbrock-1960,Muhlenbein-1991,back-1996,Griewank-1981}.
Такое преимущество и относительная простота JADE послужили
основанием для того, чтобы выбрать его в качестве основного алгоритма 
оптимизации в настоящей работе. Дополнительно для JADE была
реализована улучшенная скорость скрещивания (по алгоритму
PMCRADE~\cite{Li-PMCRADE-2011}), получившийся метод оптимизации будет
применён в последующих главах диссертации.



\section{Реализация алгоритма JADE в виде программы}
\label{sec:jade}

Часть технических моментов, касающихся выбора языка программирования и
вопросов производительности итоговой программы, была изложена в
разделе~\ref{sec:code} и остаётся верной для реализации алгоритма
стохастической оптимизации. Тем не менее, есть ряд отличий и
дополнительных факторов.

Прежде всего это связано с тем, что на момент начала работ не было
обнаружено готового к применению программного кода алгоритма JADE, поэтому его
реализация полностью выполнена автором настоящей диссертации. Это
позволило, во-первых, выбрать наиболее подходящий для реализации язык
программирования и, во-вторых, избежать возможных сложностей с
лицензированием чужого исходного кода. В частности, тип лицензии для
разработанной библиотеки оптимизации был выбран полностью
совместимым с лицензией использования программы для расчётов по
теории Ми.

Важным является вопрос об использовании генераторов псевдослучайных
чисел (ГПСЧ). Для работы стохастического оптимизатора требуется
хороший источник энтропии, однако, в стандартной библиотеке языка
Си\texttt{++} долгое время этому вопросу не уделялось должное
внимание. В стандарте языка Си\texttt{++}11, принятом в 2011 году, была
добавлена новая библиотека \verb+random+, реализующая целый ряд
ГПСЧ. Прежде всего, это Ranlux~\cite{Luscher-RNG-Ranlux-1994}, который
входит в число основных ГПСЧ для моделирования методом Монте--Карло, и
MT19937~\cite{Matsumoto-RNG-MT-1998}, использующий вихрь Мерсенна. В
последние годы MT19937 завоевал значительную популярность благодаря
своей высокой производительности и большому периоду при достаточно
хороших статистических показателях. Поэтому MT19937 является ГПСЧ
используемым по умолчанию в самых разнообразных программах, включая
широко известную Matlab Mathworks~\cite{Matlab-web}. Таким образом, для разработки
стохастического оптимизатора подходят только относительно недавние
стандарты языка, начиная с версии Си\texttt{++}11 и более поздние.

Использование относительно свежей спецификации стандарта для языка
программирования Си\texttt{++} обладает дополнительными
преимуществами. Из возможностей, появившихся в Си\texttt{++}11,
активно использовался новый синтаксис работы с перечисляемыми
коллекциями, механизм автоматического определения типа переменной на
этапе компиляции и 
задание значений по умолчанию для данных класса в
заголовочном файле. Всё вместе это заметным образом сокращает время,
необходимое для разработки новой функциональности и её дальнейшей отладки.

Современные процессоры, используемые для проведения расчётов, обычно
 содержат несколько вычислительных ядер, что позволяет
одновременно выполнять такое же количество потоков вычислений. Так как расчёты
значений целевой функции каждого индивида в рамках одного
поколения стохастической оптимизации не зависят друг от друга, то они
хорошо подходят для параллельного выполнения. Другая возможность в
полной мере задействовать вычислительные способности современных
процессоров связана со случайной природой выполняемой
оптимизации. Итоговый результат оптимизации при одних и тех же
исходных параметрах может различаться, что лучше всего заметно в
случае, когда есть несколько похожих по форме и значению локальных
минимумов, а глобальный минимум отсутствует. В этом случае финальное
значение, полученное при оптимизации, с приблизительно равной
вероятностью может оказаться в каждом из таких минимумов. Чтобы
определить возникновение подобной ситуации необходимо несколько
независимых запусков оптимизатора, каждый из которых может выполняться
на своём вычислительном ядре.

В настоящей работе для реализации был выбран последний вариант. Такой
выбор обоснован его относительной простотой и тем, что типичное
количество необходимых запусков оптимизатора при решении
задачи Ми приблизительно совпадает с числом вычислительных ядер у
современных процессоров в стационарных компьютерах (около
десяти). Впрочем, предусмотрена возможность реализации первого
варианта параллельного выполнения (когда в рамках одной оптимизации
вычислительные ядра используются для одновременного расчёта
нескольких значений целевой функции). Этот вариант станет предпочтительным
при использовании оптимизатора на суперкомпьютерном кластере, где число
вычислительных ядер заметно превышает количество необходимых запусков
оптимизации, но ещё меньше или сравнимо с числом индивидов в поколении.

Также существует возможность гибридного похода. В случае, когда
количество вычислительных ядер оказывается больше числа индивидов в
поколении, то их использование для одного запуска оптимизации
становится неэффективным из-за структуры информационных зависимостей в
алгоритме дифференциальной эволюции. Дело в том, что расчёт значений
целевой функции для очередного поколения оптимизации можно начинать
только после того, как будет завершён расчёт этих значений для
текущего поколения, так как на их основе проводится отбор лучших индивидов
для генерации нового поколения. Поэтому,
например, в случае, когда число вычислительных ядер в два раза
превышает количество индивидов в поколении, то наиболее рациональным
является запуск двух независимых оптимизаций.

Выбранный алгоритм допускает и более сложные схемы балансировки,
которые могут быть реализованы в случае необходимости. Например, если
число ядер не кратно количеству индивидов в поколении, то одним из
возможных вариантов является использование общей очереди
вычислений. Каждый из независимых запусков оптимизации размещает в ней
аргументы своих индивидов текущего поколения для расчёта целевой
функции.  Вычислительные ядра разбирают эту очередь, выполняют расчёт
и возвращают результат соответствующему процессу оптимизации. Такой
метод балансировки должен обеспечить высокую эффективность в случае,
когда число индивидов в текущем поколении в сумме по всем запускам
оптимизации заметно превышает количество вычислительных ядер.

Указанная выше особенность структуры информационных зависимостей в
алгоритме дифференциальной эволюции приводит к существованию верхнего
предела его эффективной параллелизации.  А именно, эффективно может
быть использовано число вычислительных ядер равное общему количеству
индивидов в текущем поколении всех запусков оптимизации. При
дальнейшем увеличении числа ядер величина параллельной эффективности
будет падать.

Однако, стоит учитывать, что, как правило, применение
суперкомпьютерных кластеров становится оправданным в случае
необходимости решения вычислительно трудоёмких задач, когда разовое
вычисление целевой функции само по себе требует заметного
времени. Поэтому в качестве независимого вычислителя, выполняющего
расчёт значения целевой функции, алгоритм оптимизации может вместо
одного ядра  рассматривать процессор целиком, вычислительный
узел или их группу. Общая параллельная эффективность при этом
будет определяться не только эффективностью оптимизатора, но и тем,
насколько эффективно может быть выполнено распараллеливание расчёта
целевой функции.  В качестве примера таких целевых функций можно
привести полноволновые расчёты трёхмерных моделей, использующих метод
конечных элементов.

Для реализации алгоритма, обеспечивающего параллельное выполнение
оптимизации, были выбраны программные библиотеки, поддерживающие
стандарт Message Parsing Interface (MPI). Это позволяет запускать
оптимизацию в несколько потоков как на одиночных процессорах, так и на
суперкомпьютерных кластерах. Несмотря на то, что на момент написания
диссертации поддерживался только самый простой вариант параллелизации
(количество используемых вычислительных ядер определяет число
независимых запусков оптимизатора, выполняемых одновременно) подобная
совместимость с суперкомпьютерными кластерами оказалась удобной: на
одном кластере можно запускать несколько разных задач оптимизации. 
Для этого через менеджер ресурсов и
задач кластера запрашивается необходимое число вычислительных ядер.

С помощью штатных возможностей функций MPI был реализован сбор
результатов оптимизации по всем независимым запускам, после чего
выполнялся расчёт статистических параметров: среднего значения и
среднеквадратичного отклонения. Это позволило удобным образом
организовать тестирование оптимизатора на ряде стандартных функций,
где для каждой по общепринятой методике проводится 50 запусков.
 Более подробно вопрос тестирования оптимизатора
будет рассмотрен в разделе~\ref{sec:test-jade}.

В теории разработки программного обеспечения широко известны несколько
техник, которые позволяют создавать, отлаживать, развивать и
поддерживать сложные продукты.  Их использование позволяет
значительно снизить стоимость работы программиста, или, другими
словами, существенно упростить процесс разработки.  Недостатком ряда
подобных техник является наличие дополнительных накладных расходов на
их выполнение.  В случае, если создаваемая программа оказывается
недостаточно большой и сложной, то их использование может не окупиться
в краткосрочной перспективе.  Часть техник оказываются специфичны для
каких-то языков программирования или выбранной парадигмы
(функциональной, императивной, объектно-ориентированной и~т.д.),
однако, существует несколько общих принципов, применение которых не
требует больших затрат времени. В их число входят техника сокрытия
сложности за счёт разделения абстракций и защитное программирование,
которые были использованы при разработке оптимизатора в настоящей
главе.

Защитное программирование предполагает, что каждая вызываемая функция
или подпрограммы должна сама проверять корректность и
самосогласованность используемых данных. Это заметно упрощает
разработку, так как в этом случае проверка данных и их обработка
оказываются локализованы в теле одной подпрограммы. Если на
каком-то этапе данные перестали соответствовать ожиданиям
разработчика, то такая подпрограмма сразу даст об этом знать. В
противном случае, о наличии сбоя можно будет судить только по
итоговому результату работы программы, поиск места в программе,
которое привело к ошибке, займёт значительно больше времени. После
окончания отладки программы и верификации её работы на ряде тестовых
примеров есть возможность отключить такие проверки, таким образом, их
наличие не скажется на итоговой производительности программы.

Сокрытие сложности во многом основано на более общем принципе,
согласно ему выполнение сложной задачи (которая не может быть
выполнена сразу и целиком) разбивается на несколько подзадач. В
терминах языка программирования Си\texttt{++} подзадачи называются
методами класса и функциями.  В общем случае при программировании
регламентируется количество подзадач, и возникает требование
минимальной связности между ними.  Ограничение на число подзадач
определяется особенностями человеческого восприятия. Если их 
становится более 10--15 штук, то для них резко возрастает сложность анализа 
взаимного влияния.  Эмпирически это ограничение широко известно как
<<правило одного экрана>>.  Так как при разработке декомпозиция
выражается в виде описания функции или метода класса, то не
рекомендуется делать такое разбиение, которое занимает более 25 строк
в тексте программы (это высота экрана стандартного
терминала).  С учётом строк, которые тратятся на формальное определение
функции, форматирование, логические конструкции, комментарии и тому
подобное, то в результате получается не более 10--15 логически
самостоятельных подзадач. На это число автор диссертации и
ориентировался при реализации алгоритма стохастической оптимизации.


Более важным при сокрытии сложности программы является требование
минимальной связности подзадач, что формально может быть
измерено числом передаваемых между ними логически обособленных единиц информации.
Если, например, основная задача программы
состоит в создании, модификации и дальнейшей пересылки какой-то одной
структуры данных, то только эти три подзадачи и надо включать в
декомпозицию на первом уровне разбиения из-за их слабой связности. Если
подзадача оказалась сама по себе достаточно сложной, то она
подвергается дальнейшей декомпозиции, что приводит к возникновению
иерархии подпрограмм.  Число в 10--15 подзадач, указанные ранее, это
верхний предел, достижение которого сигнализирует, что какая-то
группа подзадач скорее всего может быть выделена в отдельную подзадачу,
так как является более связанной. Например, формально это можно
понять, если такая группа подзадач использует какие-то данные, которые
не используются несколькими подзадачами до и после неё.

При реализации уже существующего алгоритма дифференциальной эволюции
разбиение на подзадачи происходит естественным образом. Сам по себе
алгоритм в тексте программы был оформлен в виде отдельной логической
единицы, объединяющей  данные и методы, необходимые
для проведения оптимизации (в Си\texttt{++} такое
объединение называется классом). Среди методов класса, реализующих
ключевые шаги алгоритма оптимизации, можно отметить селекцию, мутацию,
кроссовер, адаптацию. В них используется ряд вспомогательных методов,
которые отвечают за создание нужных случайных распределений, выборку
индивидов для генерации следующего поколения и так далее. Ряд
интерфейсных методов, которые доступны для использования внешними
программами, отвечает за настройку параметров,
инициализацию внутренних структур данных и запуск оптимизации.

Указанные рекомендации часто используются программистами на уровне,
близком к интуитивному, и могут трактоваться довольно творчески.  Это
связано с тем, что всегда существуют ограничения по времени, которое
может быть потрачено на разработку. Поэтому в небольших проектах,
связанных с исследовательской деятельностью, более рациональным может
оказаться быстрое получение результата при достаточно плохой структуре
программы. Так как она в дальнейшем не используется, то существенное
увеличение расходов на поддержание и развитие такого кода
отсутствует. В случае реализации алгоритма стохастической оптимизации
возможная область применения такой программы довольно широка. Поэтому
вопросу структурирования разрабатываемой библиотеки оптимизации было
уделено достаточно много времени.  Опыт регулярного использования
результата этой работы автором диссертации на протяжении почти 3-х лет подтвердил
правильность выбранного подхода.  В частности, когда потребовалось
добавить новую функциональность, а именно, возможность задавать
начальное значение для части индивидов в популяции, это удалось
сделать без существенных затрат сил и времени, сохранив обратную
совместимость с программами, использовавшими предыдущую версию
оптимизатора.

На этапе проектирования программы оптимизатора был допущен ряд ошибок,
большую часть которых удалось исправить при отладке и
тестировании. Оставшиеся не влияют на корректность получаемых
результатов, но несколько затрудняет использование оптимизатора.
Наиболее существенной среди них является выбор в пользу <<кодов
ошибок>> для отработки программой внештатных ситуаций вместо
использования <<механизма исключений>>.  Такое решение было принято в
целях экономии времени, так как начальное изучение методик применения
механизма исключений в Cи\texttt{++} потребовало неожиданно много
усилий, а коды ошибок являются хорошо проверенной и часто используемой
техникой при создании программ на родственном языке Си. Поэтому, среди
собственных переменных класса была объявлена специальная переменная
\verb+error_status_+, каждый метод записывает туда
значение кода ошибки, соответствующее какому-то типу случившейся
внештатной ситуации.  В подавляющем большинстве случаев дальнейшее
выполнение программы можно прекратить, сообщив пользователю о типе
возникшей ошибке и месте её возникновения, что и было
реализовано. Недостатком этого подхода является дублирование кода в
теле различных методов класса для обработки аналогичных внештатных
ситуаций, что увеличивает общий объём кода, и, как следствие,
затрудняет его дальнейшее усовершенствование.

Кроме того, применение кодов ошибок не позволяет в полной мере
разрешить ситуацию, когда проблема возникает в подпрограмме,
вычисляющей значение оптимизируемой функции. Дело в том, что эта
функция задаётся полностью независимо, поэтому у неё нет доступа к
собственным переменным класса оптимизатора и она может, например,
использовать любые свои коды ошибок. Так как библиотека оптимизатора
должна быть универсальной, то возможно два варианта решения такой
коллизии. Во-первых, в документации можно объявить коды ошибок,
которые может возвращать оптимизируемая функция. Это ограничение не
всегда может быть выполнено в случае, когда такая функция является
уже готовой к использованию достаточно сложной
программой. Дополнительно, возникнет новая связь, существование
которой обусловлено техническими моментами и, как следствие нарушает
требование минимальной логической связности между частями программы:
явная передача кода ошибки никак не обоснована в рамках задачи
оптимизации.  Во-вторых, можно отказаться от кодов ошибок и
использовать механизм исключений, который существует на уровне языка
синтаксиса Си\texttt{++}.  В случае, если оптимизируемая функция уже
использует исключения для своей работы, такой подход представляется
наиболее естественным.  Возникновение неявной связи (создаваемое
исключение передаётся на более высокий уровень иерархии подпрограмм)
частично компенсируется её однонаправленным характером и
возможностью убрать явную обработку исключений на промежуточных уровнях
иерархии.  Однако подобная возможность одновременно является и
основным недостатком механизма исключений, так как генерация
исключения и его обработка могут оказаться разнесены по самым
неожиданным частям программы.  Это может привести к существенным
затруднениям для программиста в случае необходимости разобраться, что
происходит во внештатной ситуации, поэтому при применении механизма
исключений в Си\texttt{++} необходимо вдумчиво выбирать места их
обработки в тексте программы.

В полной мере необходимость использования механизма исключений стала
понятна при практическом применении оптимизатора для создания дизайнов
наночастицы.  Дело в том, что в некоторых редких случаях входные
параметры, получаемые с помощью оптимизатора, приводили к
неустойчивому расчёту по теории Ми. Сообщение о факте возникновения
неустойчивости передавалось по механизму исключений. Так как класс
оптимизатора уже был готов и использовал коды ошибок, то было принято
компромиссное решение. В результате используются
оба подхода для разрешения внештатных ситуаций. В случае
необходимости дальнейшего улучшения оптимизатора запланированы работы
по миграции на использование только механизма исключений. Это позволит
увеличить степень унификации кода и упростит его разработку и
поддержание.

\section{Тестирование реализации алгоритма JADE}
\label{sec:test-jade}
Применение численных методов оптимизации никогда не может
гарантировать, что получится найти глобальный экстремум, а в случае
произвольной функции нет гарантий, что он будет  хотя бы
локальным экстремумом.  В предельном случае, рассмотрим ступенчатую
функцию с минимумом в выколотой точкой.  Очевидно, что вероятность
попасть в эту точку крайне мала.  Более того, если, например,
координата этой точки задана иррациональным числом, то из-за
дискретного характера представления чисел, используемого компьютером, получить в
точности это значение на выходе из оптимизатора не является возможным
даже теоретически.  Впрочем, поиск минимума подобной функции может
быть затруднительным и при использовании исключительно аналитических
методов.  Стоит отметить, что при решении физических задач подобные
функции попадаются достаточно редко.  Учитывая предпосылки,
перечисленные на странице~\pageref{ref:why-jade}, применение
стохастической оптимизации в настоящей работе является вполне
обоснованным.

Другой крайностью являются функции, у которых нет единого глобального
экстремума и/или есть большое число локальных экстремумов.  Ранее уже
обсуждался случай, когда есть несколько похожих по форме и значению
локальных минимумов, тогда стохастический оптимизатор будет находить
их с приблизительно равной вероятностью.  В случае, если локальные
минимумы сильно отличаются друг от друга, то предсказание становится
затруднительным.  Например, пусть есть два локальных минимума в общем
ровном фоне, первый --- узкий, а второй --- широкий (сравнивается ширина
на полувысоте). При прочих равных, стохастическому оптимизатору проще
найти широкий минимум. В случае если верхняя часть у первого
локального минимума во много раз больше, чем ширина второго, а у
него, в свою очередь, подобного расширения нет (например его стенки
являются практически вертикальными), то ситуация становится
неоднозначной.  С одной стороны, оптимизатору по-прежнему проще
попасть во второй минимум при случайной мутации индивидов. В то же
время, вероятность попасть в верхнюю часть первого минимума ещё
выше. Так как значение целевой функции в этой области находятся ниже
среднего фона, то в ней будут скапливаться индивиды, вырастет число
попыток найти в её окрестности глобальный минимум.  В итоге,
значительно вырастет вероятность нахождения узкого минимума.  Подобная
неоднозначность в результате работы оптимизатора и приводит к
необходимости его многократного запуска, что было подробно рассмотрена
в разделе~\ref{sec:jade}.

Ещё одним семейством функций, у которых нахождение экстремума может
оказаться достаточно сложной задачей для локальных методов
оптимизации, характеризуются особенностью в виде долины (при поиске
минимума). В этом случае можно выделить линию <<низа>> долины, при
движении вдоль которой плавно проходится значение минимума, а
в направлении поперёк неё функция резко возрастает на <<склонах>>
долины. Подобный протяжённый характер минимума вводит в заблуждение
большинство алгоритмов оптимизации: они достаточно быстро попадают в
низ долины, однако плохо справляются с движением по нему, если он
обладает заметной кривизной. Это оказывается верным для
большинства итеративных методов, в том числе и метода градиентного
спуска. Он в такой ситуации демонстрирует движение мелким
зигзагом. Типичным представителем этого семейства функций является
функция Розенброка~\cite{Rosenbrock-1960}
(см. $f_5$ в таблице~\ref{tbl:test-functions}).
% TODO check longtable positions before final release.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%      Table Funсtions     %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begingroup % Ограничиваем область видимости arraystretch
\needspace{2\baselineskip}
\renewcommand{\arraystretch}{1.6}%% Увеличение расстояния между рядами, для улучшения восприятия.
\begin{longtabu} to \textwidth {@{}>{\setlength{\baselineskip}{0.7\baselineskip}}X[1.1mc]>{\setlength{\baselineskip}{0.7\baselineskip}}X[mc]X[4]@{}}
        \caption{Тестовые функции для оптимизации, $D$ ---
          размерность. Для всех функций значение в точке глобального
          минимума равно нулю.\label{tbl:test-functions}}\\% label всегда желательно идти после caption 
        
        \toprule     %%% верхняя линейка
        Имя           &Стартовый диапазон параметров &Функция  \\ 
        \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
        \endfirsthead

        \multicolumn{3}{c}{\small\slshape (продолжение)}        \\ 
        \toprule     %%% верхняя линейка
        Имя           &Стартовый диапазон параметров &Функция  \\ 
        \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
        \endhead
        
        \multicolumn{3}{c}{\small\slshape (окончание)}        \\ 
        \toprule     %%% верхняя линейка
        Имя           &Стартовый диапазон параметров &Функция  \\ 
        \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
        \endlasthead

        \bottomrule %%% нижняя линейка
        \multicolumn{3}{r}{\small\slshape продолжение следует}  \\ 
        \endfoot   
        \endlastfoot

        сфера         &$\left[-100,\,100\right]^D$   &
        $\begin{aligned}\textstyle f_1(\mathbf{x})=\sum_{i=1}^Dx_i^2\end{aligned}$                                                        \\
        Schwefel 2.22 &$\left[-10,\,10\right]^D$     &
        $\begin{aligned}\textstyle f_2(\mathbf{x})=\sum_{i=1}^D|x_i|+\prod_{i=1}^D|x_i|\end{aligned}$                                     \\
        Schwefel 1.2  &$\left[-100,\,100\right]^D$   &$\begin{aligned}\textstyle f_3(\mathbf{x})=\sum_{i=1}^D\left(\sum_{j=1}^ix_j\right)^2\end{aligned}$                               \\
        Schwefel 2.21 &$\left[-100,\,100\right]^D$   &$\begin{aligned}\textstyle f_4(\mathbf{x})={\rmfamily max}_i\!\left\{\left|x_i\right|\right\}\end{aligned}$                             \\
        Rosenbrock    &$\left[-30,\,30\right]^D$     &$\begin{aligned}\textstyle f_5(\mathbf{x})=\sum_{i=1}^{D-1}\left[100\!\left(x_{i+1}-x_i^2\right)^2+(x_i-1)^2\right]\end{aligned}$ \\
        ступенчатая   &$\left[-100,\,100\right]^D$   &$\begin{aligned}\textstyle f_6(\mathbf{x})=\sum_{i=1}^D\big\lfloor x_i+0.5\big\rfloor^2\end{aligned}$                             \\ 
зашумлённая квартическая  &$\left[-1.28,\,1.28\right]^D$ &$\begin{aligned}\textstyle f_7(\mathbf{x})=\sum_{i=1}^Dix_i^4+rand[0,1)\end{aligned}$\vspace*{2ex}\\
        Schwefel 2.26 &$\left[-500,\,500\right]^D$   &$\begin{aligned}f_8(\mathbf{x})= &\textstyle\sum_{i=1}^D-x_i\,\sin\sqrt{|x_i|}\,+ \\
                    &\vphantom{\sum}+ D\cdot
                    418.98288727243369 \end{aligned}$\\
        Rastrigin     &$\left[-5.12,\,5.12\right]^D$ &
        $\begin{aligned}\textstyle
          f_9(\mathbf{x})=\sum_{i=1}^D\left[x_i^2-10\,\cos(2\pi
            x_i)+10\right]\end{aligned}$\vspace*{2ex}\\
  Ackley        &$\left[-32,\,32\right]^D$     &$\begin{aligned}f_{10}(\mathbf{x})= &\textstyle -20\, {\rmfamily exp}\!\left(-0.2\sqrt{\frac{1}{D}\sum_{i=1}^Dx_i^2} \right)-\\
                    &\textstyle - {\rmfamily exp}\left(\frac{1}{D}\sum_{i=1}^D\cos(2\pi x_i)  \right)  + 20 + e \end{aligned}$ \\
        Griewank      &$\left[-600,\,600\right]^D$
        &$\begin{aligned}f_{11}(\mathbf{x})= &\textstyle \frac{1}{4000}
          \sum_{i=1}^{D}x_i^2 - \prod_{i=1}^D\cos\left(x_i/\sqrt{i}\right) +1     \end{aligned}$ \vspace*{3ex} \\
        штрафная 1    &$\left[-50,\,50\right]^D$     &
        $\begin{aligned}f_{12}(\mathbf{x})= &\textstyle \frac{\pi}{D}
          \Big\{ 10\,\sin^2(\pi y_1) +\\ &+
          \textstyle \sum_{i=1}^{D-1}(y_i-1)^2\left[1+10\,\sin^2(\pi
              y_{i+1})\right] +\\ &+(y_D-1)^2 \Big\} +\textstyle\sum_{i=1}^D u(x_i,\,10,\,100,\,4)            \end{aligned}$ \vspace*{2ex} \\
        штрафная 2    &$\left[-50,\,50\right]^D$     &
        $\begin{aligned}f_{13}(\mathbf{x})= &\textstyle 0.1
          \Big\{\sin^2(3\pi x_1) +\\ &+
          \textstyle \sum_{i=1}^{D-1}(x_i-1)^2\left[1+\sin^2(3 \pi
              x_{i+1})\right] + \\ &+(x_D-1)^2\left[1+\sin^2(2\pi
              x_D)\right] \Big\} +\\ &+\textstyle\sum_{i=1}^D u(x_i,\,5,\,100,\,4)            \end{aligned}$            \vspace*{1ex}\\
        \midrule %%% тонкий разделитель
        \multicolumn{3}{@{}p{\textwidth}}{%
            \vspace*{-4ex}% этим подтягиваем повыше
            \hspace*{2.5em}% абзацный отступ - требование ГОСТ 2.105
            Примечание "---  Для функций $f_{12}$ и $f_{13}$
            используется $y_i = 1 + \frac{1}{4}(x_i+1)$ и
            $u(x_i,\,a,\,k,\,m)=\begin{cases}
k(x_i-a)^m,\quad &x_i >a\\[-0.5em]
0,\quad &-a\leq x_i \leq a\\[-0.5em]
k(-x_i-a)^m,\quad &x_i <-a
\end{cases}$  }   \\        \bottomrule %%% нижняя линейка 
\end{longtabu} \endgroup

Так как заранее предугадать тип функции, который попадётся
оптимизатору при решении произвольной физической задачи не
представляется возможным, то для проверки его работы был использован
стандартный набор
функций~\cite{Schwefel-1981,Rosenbrock-1960,Muhlenbein-1991,back-1996,Griewank-1981}
(см. таблицу~\ref{tbl:test-functions}), часто применяемый другими
авторами в целях тестирования. У каждой функции приводится её имя или
краткое описание, диапазон параметров, внутри которого происходит
поиск минимума, и выражение для вычисления. Всё функции могут
использовать произвольное число независимых переменных, определяемое
размерностью $D$.

Тестирование проводилось в два этапа. На первом сравнивался результат
оптимизатора JADE\texttt{++}, реализованного в рамках настоящей
работы, с оригинальным алгоритмом JADE и другими алгоритмами (были
использованы данные из публикации~\cite{Jingqiao-JADE-2009},
таблицы~\ref{tbl:opt-results-book-30d}
и~\ref{tbl:opt-results-book-100d}). На втором этапе сравнивались
результаты оригинального алгоритма JADE и нескольких его модификаций,
реализованных в настоящей работе
(таблицы~\ref{tbl:opt-results-jade-30d}
и~\ref{tbl:opt-results-jade-100d}).  В этих таблицах приводится
результат оптимизации различными алгоритмами, для удобства восприятия
среднее значение и среднеквадратичное отклонение (указано в скобках)
группируются для каждого сочетания тестовой функции и
алгоритма. Лучший результат для каждой функции дополнительно выделен
шрифтом с полужирным начертанием.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%      Table 30D   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begingroup % Ограничиваем область видимости arraystretch
%% http://tex.stackexchange.com/questions/278362/apply-italic-formatting-to-every-other-row
%\newcounter{rowcnt}
\newcommand\z{\bfseries}
\renewcommand\altshape{\ifthenelse{\therowcnt = 0 }{%
}{
  \ifnumodd{\value{rowcnt}}{}{\vspace*{-0.8ex}}}
}
\newcolumntype{A}{ >{\altshape}X[1mc]}
\AtBeginEnvironment{tabular}{\setcounter{rowcnt}{1}}
\AtEndEnvironment{tabular}{\setcounter{rowcnt}{0}}

\needspace{2\baselineskip}
\renewcommand{\arraystretch}{0.9}%% Увеличение расстояния между рядами, для улучшения восприятия.
\begin{longtabu} to \textwidth {@{}X[0.3ml]X[0.7mc]AAAA>{\setlength{\baselineskip}{0.7\baselineskip}}AA<{\stepcounter{rowcnt}}@{}}
% \begin{longtabu} to \textwidth {@{}X[0.2ml]X[1mc]X[1mc]X[1mc]X[1mc]X[1mc]>{\setlength{\baselineskip}{0.7\baselineskip}}X[1mc]X[1mc]@{}}
  \caption{Сравнение различных алгоритмов оптимизации. Указанны
    среднее значение и среднеквадратичное отклонение (в скобках) результата
    оптимизации после фиксированного числа итераций (столбец Gen) и для 50 запусков
    каждого алгоритма. Для каждой функции бралось число независимых
    переменных $D=30$.\label{tbl:opt-results-book-30d}}\vspace*{1ex}\\% label всегда желательно идти после caption
  % \vspace*{1ex}     \\
  \toprule %%% верхняя линейка  
\setcounter{rowcnt}{0} &Gen & JADE\texttt{++} & JADE & jDE & SaDE
& DE/rand /1/bin & PSO \\ 
 \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
 \endfirsthead
 \multicolumn{8}{c}{\small\slshape (продолжение)} \\ 
 \toprule %%% верхняя линейка
 \setcounter{rowcnt}{0} &Gen & JADE\texttt{++} & JADE & jDE & SaDE
& DE/rand /1/bin & PSO \\ 
 \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
 \endhead
 \multicolumn{8}{c}{\small\slshape (окончание)} \\ 
 \toprule %%% верхняя линейка
\setcounter{rowcnt}{0} &Gen & JADE\texttt{++} & JADE & jDE & SaDE
& DE/rand /1/bin & PSO \\ 
 \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
 \endlasthead
 \bottomrule %%% нижняя линейка
 \multicolumn{8}{r}{\small\slshape продолжение следует}     \\ 
 \endfoot 
 \endlastfoot
 
$f_{1}$  & 1500 & 3.1E-54  &\z1.3E-54 & 2.5E-28   & 4.5E-20   & 9.8E-14   & 9.6E-42   \\\nopagebreak
    &      & (2.1E-53)& (9.2E-54) & (3.5E-28) & (6.9E-20) & (8.4E-14) & (2.7E-41) \\
$f_{2}$  & 2000 & 6.0E-23  & 3.9E-22   & \z1.5E-23   & 1.9E-14   & 1.6E-09   & 9.3E-21   \\\nopagebreak
    &      & (3.0E-22)& (2.7E-21) & (1.0E-23) & (1.1E-14) & (1.1E-09) & (6.3E-20) \\
$f_{3}$  & 5000 & \z2.7E-92  & 6.0E-87   & 5.2E-14   & 9.0E-37   & 6.6E-11   & 2.5E-19   \\\nopagebreak
    &      & (1.8E-91)& (1.9E-86) & (1.1E-13) & (5.4E-36) & (8.8E-11) & (3.9E-19) \\
$f_{4}$  & 5000 & 8.1E-07  & \z4.3E-66   & 1.4E-15   & 7.4E-11   & 4.2E-01   & 4.4E-14   \\\nopagebreak
    &      & (2.8E-07)& (1.2E-65) & (1.0E-15) & (1.8E-10) & (1.1E+00) & (9.3E-14) \\
$f_{5}$  & 3000 & \z8.0E-02  & 3.2E-01   & 1.3E+01   & 2.1E+01   & 2.1E+00   & 2.5E+01   \\\nopagebreak
    &      & (5.6E-01)& (1.1E+00) & (1.4E+01) & (7.8E+00) & (1.5E+00) & (3.2E+01) \\
$f_{6}$  & 100  & 6.9E+00  & \z5.6E+00   & 1.0E+03   & 9.3E+02   & 4.7E+03   & 4.5E+01   \\\nopagebreak
    &      & (1.8E+00)& (1.6E+00) & (2.2E+02) & (1.8E+02) & (1.1E+03) & (2.4E+01) \\
$f_{7}$  & 3000 & \z6.3E-04  & 6.8E-04   & 3.3E-03   & 4.8E-03   & 4.7E-03   & 2.5E-03   \\\nopagebreak
    &      & (2.3E-04)& (2.5E-04) & (8.5E-04) & (1.2E-03) & (1.2E-03) & (1.4E-03) \\
$f_{8}$  & 1000 & 5.6E-05  & 7.1E+00   & \z7.9E-11   & 4.7E+00   & 5.9E+03   & 2.4E+03   \\\nopagebreak
    &      & (4.0E-05)& (2.8E+01) & (1.3E-10) & (3.3E+01) & (1.1E+03) & (6.7E+02) \\
$f_{9}$  & 1000 & 2.3E-04  & \z1.4E-04   & 1.5E-04   & 1.2E-03   & 1.8E+02   & 5.2E+01   \\\nopagebreak
    &      & (1.2E-04)& (6.5E-05) & (2.0E-04) & (6.5E-04) & (1.3E+01) & (1.6E+01) \\
$f_{10}$ & 500  & 6.4E-09  & \z3.0E-09   & 3.5E-04   & 2.7E-03   & 1.1E-01   & 4.6E-01   \\\nopagebreak
    &      & (9.8E-09)& (2.2E-09) & (1.0E-04) & (5.1E-04) & (3.9E-02) & (6.6E-01) \\
$f_{11}$ & 500  & \z1.1E-07  & 2.0E-04   & 1.9E-05   & 7.8E-04  & 2.0E-01   & 1.3E-02   \\\nopagebreak
    &      & (7.8E-07)& (1.4E-03) & (5.8E-05) & (1.2E-03)  & (1.1E-01) & (1.7E-02) \\
$f_{12}$ & 500  & \z2.6E-16  & 3.8E-16   & 1.6E-07   & 1.9E-05   & 1.2E-02   & 1.9E-01   \\\nopagebreak
    &      & (4.4E-16)& (8.3E-16) & (1.5E-07) & (9.2E-06) & (1.0E-02) & (3.9E-01) \\
$f_{13}$ & 500  & \z1.2E-15  & \z1.2E-15   & 1.5E-06   & 6.1E-05   & 7.5E-02   & 2.9E-03   \\\nopagebreak
    &      & (3.4E-15)& (2.8E-15) & (9.8E-07) & (2.0E-05) & (3.8E-02) & (4.8E-03) \\

    % \vspace*{1ex}     \\
%         \midrule%%% тонкий разделитель
%         \multicolumn{3}{@{}p{\textwidth}}{%
%             % \vspace*{-4ex}% этим подтягиваем повыше
%             % \hspace*{2.5em}% абзацный отступ - требование ГОСТ 2.105
%             Примечание "---  Для функций $f_{12}$ и $f_{13}$
%             используется $y_i = 1 + \frac{1}{4}(x_i+1)$ и
%             $u(x_i,\,a,\,k,\,m)=\begin{cases}
% k(x_i-a)^m,\quad  & x_i >a     \\[-0.5em]
% 0,\quad           & -a\leq x_i \leq a        \\[-0.5em]
% k(-x_i-a)^m,\quad & x_i <-a
% \end{cases}$  }     \\
\bottomrule %%% нижняя линейка 
\end{longtabu} \endgroup


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%      Table 100D   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begingroup % Ограничиваем область видимости arraystretch
%% http://tex.stackexchange.com/questions/278362/apply-italic-formatting-to-every-other-row
% \newcounter{rowcnt}
\newcommand\z{\bfseries}
\renewcommand\altshape{\ifthenelse{\therowcnt = 0 }{%
}{
  \ifnumodd{\value{rowcnt}}{}{\vspace*{-0.8ex}}}
}
\newcolumntype{A}{ >{\altshape}X[1mc]}
\AtBeginEnvironment{tabular}{\setcounter{rowcnt}{1}}
\AtEndEnvironment{tabular}{\setcounter{rowcnt}{0}}

\needspace{2\baselineskip}
\renewcommand{\arraystretch}{0.9}%% Увеличение расстояния между рядами, для улучшения восприятия.
\begin{longtabu} to \textwidth {@{}X[0.3ml]X[0.7mc]AAAA>{\setlength{\baselineskip}{0.7\baselineskip}}AA<{\stepcounter{rowcnt}}@{}}
% \begin{longtabu} to \textwidth {@{}X[0.2ml]X[1mc]X[1mc]X[1mc]X[1mc]X[1mc]>{\setlength{\baselineskip}{0.7\baselineskip}}X[1mc]X[1mc]@{}}
  \caption{Аналогично таблице~\ref{tbl:opt-results-book-30d} для числа независимых
    переменных $D=100$.\label{tbl:opt-results-book-100d}}\vspace*{1ex}\\% label всегда желательно идти после caption

  \toprule %%% верхняя линейка  
\setcounter{rowcnt}{0} &Gen & JADE\texttt{++} & JADE & jDE & SaDE
& DE/rand /1/bin & PSO \\ 

 \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
 \endfirsthead

 \multicolumn{8}{c}{\small\slshape (продолжение)} \\ 
 \toprule %%% верхняя линейка
\setcounter{rowcnt}{0} &Gen & JADE\texttt{++} & JADE & jDE & SaDE
& DE/rand /1/bin & PSO \\ 
 \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
 \endhead
 
 \multicolumn{8}{c}{\small\slshape (окончание)} \\ 
 \toprule %%% верхняя линейка
\setcounter{rowcnt}{0} &Gen & JADE\texttt{++} & JADE & jDE & SaDE
& DE/rand /1/bin & PSO \\ 
 \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
 \endlasthead

 \bottomrule %%% нижняя линейка
 \multicolumn{8}{r}{\small\slshape продолжение следует}     \\ 
 \endfoot 
 \endlastfoot
 
$f_{1}$ &2000 & 7.5e-67   &\z 5.4E-67   & 5.0E-15   & 2.9E-08   & 3.5E+01   & 6.0E-11   \\\nopagebreak
   &     & (1.9e-66) & (1.6E-66) & (1.7E-15) & (3.2E-08) & (9.6E+00) & (2.5E-10) \\
$f_{2}$ &3000 &\z 4.2e-51   & 9.2E-51   & 4.1E-15   & 1.7E-05   & 2.3E+00   & 2.8E-04   \\\nopagebreak
   &     & (7.4e-51) & (2.2E-50) & (1.1E-15) & (3.8E-06) & (5.6E-01) & (1.3E-03) \\
$f_{3}$ &8000 &\z 1.7e-37   & 2.2E-37   & 5.4E-02   & 2.4E-13   & 2.1E+05   & 1.2E+02   \\\nopagebreak
   &     & (5.6e-37) & (2.5E-37) & (2.7E-02) & (5.2E-13) & (3.1E+04) & (6.7E+01) \\
$f_{4}$ &15000& 2.4e-02   &\z 3.2E-71   & 3.1E-09   & 1.1E+00   & 9.3E+01   & 4.9E+01   \\\nopagebreak
   &     & (5.7e-03) & (8.3E-71) & (5.9E-10) & (4.0E-01) & (2.8E+00) & (2.5E+01) \\
$f_{5}$ &6000 &\z 3.2e-01   & 4.0E-01   & 7.2E+01   & 9.4E+01   & 9.5E+01   & 1.3E+02   \\\nopagebreak
   &     & (1.1e+00) & (1.2E+00) & (1.1E+01) & (4.0E-01) & (1.4E+01) & (4.8E+01) \\
$f_{6}$ &100  & 1.5e+02   &\z 1.2E+02   & 7.1E+04   & 3.3E+04   & 1.8E+05   & 1.9E+04   \\\nopagebreak
   &     & (1.7e+01) & (1.3E+01) & (6.0E+03) & (2.1E+03) & (1.8E+04) & (4.5E+03) \\
$f_{7}$ &6000 &\z 6.8e-04   & 7.8E-04   & 8.1E-03   & 1.0E-02   & 2.9E-02   & 9.2E-03   \\\nopagebreak
   &     & (1.3e-04) & (1.4E-04) & (9.0E-04) & (4.9E-03) & (5.7E-03) & (2.6E-03) \\
$f_{8}$ &1000 & 8.6e+03   & 8.6E+03   &\z 4.9E+03   & 5.4E+03   & 3.2E+04   & 9.5E+03   \\\nopagebreak
   &     & (3.9e+02) & (4.2E+02) & (4.1E+02) & (3.7E+02) & (4.7E+02) & (1.3E+03) \\
$f_{9}$ &3000 & 3.0e-01   & 2.0E-01   &\z 2.1E-04   & 9.1E-03   & 8.6E+02   & 3.4E+02   \\\nopagebreak
   &     & (5.3e-02) & (3.7E-02) & (2.1E-04) & (1.8E-03) & (2.2E+01) & (4.4E+01) \\
$f_{10}$&500  & 5.0e-07   &\z 4.2E-07   & 8.5E-01   & 1.6E+00   & 1.5E+01   & 3.6E+00   \\\nopagebreak
   &     & (1.1e-07) & (1.2E-07) & (1.2E-01) & (1.2E-01) & (5.8E-01) & (9.3E-01) \\
$f_{11}$&500  &\z 1.5e-04   &\z 1.5E-04   & 1.1E+00   & 1.1E+00   & 2.7E+02   & 1.0E+00   \\\nopagebreak
   &     & (1.0e-03) & (1.0E-03) & (2.0E-02) & (1.8E-02) & (4.4E+01) & (5.6E-01) \\
$f_{12}$&500  & 6.2e-04   &\z 2.8E-13   & 4.0E+00   & 2.4E+00   & 1.8E+09   & 1.1E+01   \\\nopagebreak
   &     & (4.4e-03) & (9.8E-13) & (6.8E-01) & (3.9E-01) & (5.1E+08) & (3.4E+00) \\
$f_{13}$&500  & 8.4e-12   &\z 5.8E-12   & 3.1E+01   & 1.2E+01   & 2.4E+09   & 9.8E+01   \\\nopagebreak
   &     & (6.2e-12) & (5.5E-12) & (7.8E+00) & (1.8E+00) & (1.1E+09) & (2.4E+01) \\

\bottomrule %%% нижняя линейка 
\end{longtabu} \endgroup

Надо отметить, что оригинальный алгоритм JADE существует в двух
модификациях: с опцией запоминания наиболее удачных попыток всего
предыдущего поколения улучшить решение и без неё.  Сравнение в
статье~\cite{Jingqiao-JADE-2009} показало, что наличие этой опции
обеспечивает более надёжную работу алгоритма в условиях недостатка
вычислительных ресурсов. Другими словами, без этой опции
алгоритму JADE необходимо большее число индивидов в поколении для
достижения того же результата. Недостаток этой опции проявляется
потом, когда индивидов оказывается с некоторым избытком, тогда
результат получается несколько лучше без неё.

Особенно хорошо это заметно при сравнении
таблиц~\ref{tbl:opt-results-book-30d}
и~\ref{tbl:opt-results-book-100d}, которые отличаются числом
независимых переменных $D$, используемых тестовыми функциями. В
таблице~\ref{tbl:opt-results-book-30d} $D=30$, число индивидов в
поколении стохастической оптимизации $N_{\rmfamily ind} = 100$, а в
таблице~\ref{tbl:opt-results-book-100d} $D=100$ и
$N_{\rmfamily ind} = 400$. Как уже отмечалось в
работе~\cite{Jingqiao-JADE-2009}, несмотря на то, что формально для
случая $D=30$ на одну независимую переменную приходится меньшее
количество индивидов, для случая $D=100$ наблюдается некий дефицит количества
индивидов. Это позволяет лучше раскрыться возможностям алгоритма JADE
с опцией запоминания, а именно: для тех тестовых функций, где он
выигрывал у остальных алгоритмов в случае $D=30$, отношение выигрыша, как правило, увеличивается или слабо меняется для случая $D=100$. Для
тех тестовых случаев, где алгоритм JADE отставал --- наоборот, относительное
отставание стало меньше (за
небольшим исключением, которое будет рассмотрено ниже).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%      Table 30D  JADE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begingroup % Ограничиваем область видимости arraystretch
%% http://tex.stackexchange.com/questions/278362/apply-italic-formatting-to-every-other-row
% \newcounter{rowcnt}
\newcommand\z{\bfseries}
\renewcommand\altshape{\ifthenelse{\therowcnt = 0 }{%
}{
  \ifnumodd{\value{rowcnt}}{}{\vspace*{-0.8ex}}}
}
\newcolumntype{A}{ >{\altshape}X[1mc]}
\AtBeginEnvironment{tabular}{\setcounter{rowcnt}{1}}
\AtEndEnvironment{tabular}{\setcounter{rowcnt}{0}}

\needspace{2\baselineskip}
\renewcommand{\arraystretch}{0.9}%% Увеличение расстояния между рядами, для улучшения восприятия.
\begin{longtabu} to \textwidth {@{}X[0.3ml]X[0.7mc]AAAAA<{\stepcounter{rowcnt}}@{}}
% \begin{longtabu} to \textwidth {@{}X[0.2ml]X[1mc]X[1mc]X[1mc]X[1mc]X[1mc]>{\setlength{\baselineskip}{0.7\baselineskip}}X[1mc]X[1mc]@{}}
  \caption{Аналогично таблице~\ref{tbl:opt-results-book-30d} для числа независимых
    переменных $D=30$. Сравнение реализованных модификаций алгоритма
    JADE с оригинальной версией\label{tbl:opt-results-jade-30d}}\vspace*{1ex}\\% label всегда желательно идти после caption
  % \vspace*{1ex}     \\

  \toprule %%% верхняя линейка
  \setcounter{rowcnt}{0} &\multirow{2}{*}{Gen} & \multirow{2}{*}{JADE} &
  \multicolumn{2}{c}{JADE\texttt{}++} &   \multicolumn{2}{c}{PMCRADE}\\
  \setcounter{rowcnt}{0} & & & ranlux48 & MT19937 & ranlux48 & MT19937 \\

 \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
 \endfirsthead

 \multicolumn{7}{c}{\small\slshape (продолжение)} \\ 
 \toprule %%% верхняя линейка
  \setcounter{rowcnt}{0} &\multirow{2}{*}{Gen} & \multirow{2}{*}{JADE} &
  \multicolumn{2}{c}{JADE\texttt{}++} &   \multicolumn{2}{c}{PMCRADE}\\
  \setcounter{rowcnt}{0} & & & ranlux48 & MT19937 & ranlux48 & MT19937 \\
 \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
 \endhead
 
 \multicolumn{7}{c}{\small\slshape (окончание)} \\ 
 \toprule %%% верхняя линейка
  \setcounter{rowcnt}{0} &\multirow{2}{*}{Gen} & \multirow{2}{*}{JADE} &
  \multicolumn{2}{c}{JADE\texttt{}++} &   \multicolumn{2}{c}{PMCRADE}\\
  \setcounter{rowcnt}{0} & & & ranlux48 & MT19937 & ranlux48 & MT19937 \\
 \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
 \endlasthead

 \bottomrule %%% нижняя линейка
 \multicolumn{7}{r}{\small\slshape продолжение следует}     \\ 
 \endfoot 
 \endlastfoot
 
$f_{1}$  & 1500 & 1.3E-54   & 3.1E-54   & 1.0e-57   & 7.4e-79  &\z 2.9e-79   \\\nopagebreak
    &      & (9.2E-54) & (2.1E-53) & (6.8e-57) & (1.3e-78)& (4.4e-79) \\
$f_{2}$  & 2000 & 3.9E-22   & 6.0E-23   & 2.8e-23   &\z 6.4e-52  & 1.2e-51   \\\nopagebreak
    &      & (2.7E-21) & (3.0E-22) & (1.3e-22) & (1.4e-51)& (4.1e-51) \\
$f_{3}$  & 5000 & 6.0E-87   & 2.7E-92   & 5.6e-93   & 4.6e-93  &\z 6.3e-95   \\\nopagebreak
    &      & (1.9E-86) & (1.8E-91) & (2.1e-92) & (1.7e-92)& (2.7e-94) \\
$f_{4}$  & 5000 & 4.3E-66   & 8.1E-07   & 8.1e-07   & 1.7e-33  &\z 1.5e-33   \\\nopagebreak
    &      & (1.2E-65) & (2.8E-07) & (3.6e-07) & (8.9e-33)& (1.1e-32) \\
$f_{5}$  & 3000 & 3.2E-01   &\z 8.0E-02   &\z 8.0e-02   & 1.6e-01  &\z 8.0e-02   \\\nopagebreak
    &      & (1.1E+00) & (5.6E-01) & (5.6e-01) & (7.8e-01)& (5.6e-01) \\
$f_{6}$  & 100  & 5.6E+00   & 6.9E+00   & 7.3e+00   & 4.2e+00  &\z 4.0e+00   \\\nopagebreak
    &      & (1.6E+00) & (1.8E+00) & (1.8e+00) & (1.2e+00)& (1.4e+00) \\
$f_{7}$  & 3000 & 6.8E-04   & 6.3E-04   & 6.1e-04   & 5.9e-04  &\z 5.3e-04   \\\nopagebreak
    &      & (2.5E-04) & (2.3E-04) & (2.7e-04) & (2.2e-04)& (1.7e-04) \\  
$f_{8}$  & 1000 & 7.1E+00   & 5.6E-05   & 2.4e+00   &\z 5.2e-05   & 4.7e+00   \\\nopagebreak
    &      & (2.8E+01) & (4.0E-05) & (1.7e+01) & (4.7e-05)& (2.3e+01) \\
$f_{9}$  & 1000 & 1.4E-04   & 2.3E-04   & 2.3e-04   &\z 3.9e-06  & 5.2e-06   \\\nopagebreak
    &      & (6.5E-05) & (1.2E-04) & (1.1e-04) & (4.3e-06)& (8.5e-06) \\
$f_{10}$ & 500  & 3.0E-09   & 6.4E-09   & 4.2e-09   &\z 7.2e-12  & 7.4e-12   \\\nopagebreak
    &      & (2.2E-09) & (9.8E-09) & (3.3e-09) & (3.6e-12)& (3.7e-12) \\
$f_{11}$ & 500  & 2.0E-04   & 1.1E-07   &\z 2.8e-13   &2.0e-04  & 1.5e-04   \\\nopagebreak
    &      & (1.4E-03) & (7.8E-07) & (1.9e-12) &(1.4e-03)& (1.0e-03) \\
$f_{12}$ & 500  & 3.8E-16   & 2.6E-16   & 4.6e-16   &\z 1.2e-22  & 1.7e-22   \\\nopagebreak
    &      & (8.3E-16) & (4.4E-16) & (8.5e-16) & (1.9e-22)& (4.9e-22) \\
$f_{13}$ & 500  & 1.2E-15   & 1.2E-15   & 2.1e-15   & 1.1e-21  &\z 7.9e-22   \\\nopagebreak
    &      & (2.8E-15) & (3.4E-15) & (5.6e-15) & (1.2e-21)& (8.7e-22) \\

    % \vspace*{1ex}     \\
%         \midrule%%% тонкий разделитель
%         \multicolumn{3}{@{}p{\textwidth}}{%
%             % \vspace*{-4ex}% этим подтягиваем повыше
%             % \hspace*{2.5em}% абзацный отступ - требование ГОСТ 2.105
%             Примечание "---  Для функций $f_{12}$ и $f_{13}$
%             используется $y_i = 1 + \frac{1}{4}(x_i+1)$ и
%             $u(x_i,\,a,\,k,\,m)=\begin{cases}
% k(x_i-a)^m,\quad  & x_i >a     \\[-0.5em]
% 0,\quad           & -a\leq x_i \leq a        \\[-0.5em]
% k(-x_i-a)^m,\quad & x_i <-a
% \end{cases}$  }     \\
\bottomrule %%% нижняя линейка 
\end{longtabu} \endgroup

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%      Table 100D   JADE %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begingroup % Ограничиваем область видимости arraystretch
%% http://tex.stackexchange.com/questions/278362/apply-italic-formatting-to-every-other-row
% \newcounter{rowcnt}
\newcommand\z{\bfseries}
\renewcommand\altshape{\ifthenelse{\therowcnt = 0 }{%
}{
  \ifnumodd{\value{rowcnt}}{}{\vspace*{-0.8ex}}}
}
\newcolumntype{A}{ >{\altshape}X[1mc]}
\AtBeginEnvironment{tabular}{\setcounter{rowcnt}{1}}
\AtEndEnvironment{tabular}{\setcounter{rowcnt}{0}}

\needspace{2\baselineskip}
\renewcommand{\arraystretch}{0.9}%% Увеличение расстояния между рядами, для улучшения восприятия.
\begin{longtabu} to \textwidth {@{}X[0.3ml]X[0.7mc]AAAAA<{\stepcounter{rowcnt}}@{}}
% \begin{longtabu} to \textwidth {@{}X[0.2ml]X[1mc]X[1mc]X[1mc]X[1mc]X[1mc]>{\setlength{\baselineskip}{0.7\baselineskip}}X[1mc]X[1mc]@{}}
  \caption{Аналогично таблице~\ref{tbl:opt-results-jade-30d} для числа независимых
    переменных $D=100$.\label{tbl:opt-results-jade-100d}}\vspace*{1ex}\\% label всегда желательно идти после caption
  \toprule %%% верхняя линейка  
  \setcounter{rowcnt}{0} &\multirow{2}{*}{Gen} & \multirow{2}{*}{JADE} &
  \multicolumn{2}{c}{JADE\texttt{}++} &   \multicolumn{2}{c}{PMCRADE}\\
  \setcounter{rowcnt}{0} & & & ranlux48 & MT19937 & ranlux48 & MT19937 \\

 \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
 \endfirsthead

 \multicolumn{7}{c}{\small\slshape (продолжение)} \\ 
 \toprule %%% верхняя линейка
  \setcounter{rowcnt}{0} &\multirow{2}{*}{Gen} & \multirow{2}{*}{JADE} &
  \multicolumn{2}{c}{JADE\texttt{}++} &   \multicolumn{2}{c}{PMCRADE}\\
  \setcounter{rowcnt}{0} & & & ranlux48 & MT19937 & ranlux48 & MT19937 \\
 \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
 \endhead
 
 \multicolumn{7}{c}{\small\slshape (окончание)} \\ 
 \toprule %%% верхняя линейка
  \setcounter{rowcnt}{0} &\multirow{2}{*}{Gen} & \multirow{2}{*}{JADE} &
  \multicolumn{2}{c}{JADE\texttt{}++} &   \multicolumn{2}{c}{PMCRADE}\\
  \setcounter{rowcnt}{0} & & & ranlux48 & MT19937 & ranlux48 & MT19937 \\
 \midrule %%% тонкий разделитель. Отделяет названия столбцов. Обязателен по ГОСТ 2.105 пункт 4.4.5 
 \endlasthead

 \bottomrule %%% нижняя линейка
 \multicolumn{7}{r}{\small\slshape продолжение следует}     \\ 
 \endfoot 
 \endlastfoot
 
$f_1$ &2000 & 5.4E-67   & 7.5e-67   & 2.4e-66   &\z 2.4e-67   & 1.3e-66   \\\nopagebreak
   &     & (1.6E-66) & (1.9e-66) & (1.0e-65) & (4.6e-67) & (6.2e-66) \\
$f_2$ &3000 & 9.2E-51   &\z 4.2e-51   & 1.7e-50   & 5.9e-51   & 4.6e-51   \\\nopagebreak
   &     & (2.2E-50) & (7.4e-51) & (3.8e-50) & (1.5e-50) & (1.1e-50) \\
$f_3$ &8000 & 2.2E-37   & 1.7e-37   & 4.1e-38   & 4.3e-38   &\z 3.6e-38   \\\nopagebreak
   &     & (2.5E-37) & (5.6e-37) & (5.9e-38) & (5.2e-38) & (5.4e-38) \\
$f_4$ &15000&\z 3.2E-71   & 2.4e-02   & 2.4e-02   & 2.3e-02   & 2.4e-02   \\\nopagebreak
   &     & (8.3E-71) & (5.7e-03) & (4.7e-03) & (4.7e-03) & (5.7e-03) \\
$f_5$ &6000 & 4.0E-01   & 3.2e-01   &\z 2.4e-01   &\z 2.4e-01   & 4.0e-01   \\\nopagebreak
   &     & (1.2E+00) & (1.1e+00) & (9.5e-01) & (9.5e-01) & (1.2e+00) \\
$f_6$ &100  &\z 1.2E+02   & 1.5e+02   & 1.5e+02   & 1.5e+02   & 1.4e+02   \\\nopagebreak
   &     & (1.3E+01) & (1.7e+01) & (1.8e+01) & (1.8e+01) & (1.4e+01) \\
$f_7$ &6000 & 7.8E-04   &\z 6.8e-04   & 7.3e-04   & 7.1e-04   & 7.1e-04   \\\nopagebreak
   &     & (1.4E-04) & (1.3e-04) & (1.3e-04) & (1.5e-04) & (1.4e-04) \\
$f_8$ &1000 &\z 8.6E+03   &\z 8.6e+03   &\z 8.6e+03   &\z 8.6e+03   &\z 8.6e+03   \\\nopagebreak
   &     & (4.2E+02) & (3.9e+02) & (4.9e+02) & (3.7e+02) & (3.9e+02) \\
$f_9$ &3000 &\z 2.0E-01   & 3.0e-01   & 3.0e-01   & 2.8e-01   & 2.8e-01   \\\nopagebreak
   &     & (3.7E-02) & (5.3e-02) & (5.2e-02) & (5.2e-02) & (3.8e-02) \\
$f_{10}$ &500  &\z 4.2E-07   & 5.0e-07   & 4.6e-07   & 4.7e-07   & 4.5e-07   \\\nopagebreak
   &     & (1.2E-07) & (1.1e-07) & (1.2e-07) & (1.3e-07) & (1.7e-07) \\
$f_{11}$&500  & 1.5E-04   & 1.5e-04   &\z 1.4e-11   & 1.5e-04   & 2.0e-04   \\\nopagebreak
   &     & (1.0E-03) & (1.0e-03) & (9.4e-12) & (1.0e-03) & (1.4e-03) \\
$f_{12}$ &500  & 2.8E-13   & 6.2e-04   & 1.4e-13   & 1.5e-13   &\z 1.3e-13   \\\nopagebreak
   &     & (9.8E-13) & (4.4e-03) & (1.1e-13) & (1.6e-13) & (1.0e-13) \\
$f_{13} $&500  &\z 5.8E-12   & 8.4e-12   & 1.7e-11   & 1.1e-11   & 1.1e-11   \\\nopagebreak
   &     & (5.5E-12) & (6.2e-12) & (4.0e-11) & (1.4e-11) & (1.5e-11) \\

\bottomrule %%% нижняя линейка 
\end{longtabu} \endgroup

В таблицах~\ref{tbl:opt-results-jade-30d}
и~\ref{tbl:opt-results-jade-100d} сравнивались результаты
оригинального алгоритма JADE и нескольких его модификаций,
реализованных в настоящей работе. Рассмотрены случаи использования
алгоритмов ГПСЧ ranlux48 и MT19937, а так же применение двух разных
методов адаптации: оригинального и PMCRADE~\cite{Li-PMCRADE-2011}).

В случае $D=30$ видно, что чаще всего лучший результат получается при
использовании адаптации по методу PMCRADE. Различие в алгоритмах ГПСЧ
на результат влияет слабо, оно наиболее заметно с точки зрения общей
вычислительной сложности: использование ГПСЧ ranlux48 увеличило
время выполнения 50 прогонов оптимизатора на всех тестовых функциях
почти в три раза по сравнению с применением алгоритма MT19937 (c
56~минут до 2~часов 40~минут).
% jade MT19937 w/o PMCRADE - 3h 40 min
% jade ranlux w/o PMCRADE -2h 20 min
% jade ranlux  PMCRADE -2h 40 min
% jade MT19937  PMCRADE - 56 min

В случае $D=100$ все алгоритмы продемонстрировали приблизительно
одинаковый итоговый результат, что оказывается весьма удобным для
 анализа исключений, которые были упомянуты
ранее. Дело в том, что $f_8$--$f_{13}$ из
таблицы~\ref{tbl:test-functions} используют тригонометрические
функции, а это приводит к существованию большого числа похожих локальных
минимумов. Такое поведение затрудняет нахождение единственного
глобального минимума.  Как уже отмечалось, применение стохастических
методов оптимизации не может гарантировать нахождение глобального
минимума, возникающие исключения и относятся к подобному случаю. В
общепринятой методологии используется простое усреднение по всем
прогонам оптимизации без какого-либо предварительного отбора.  Случаи,
когда оптимизатор не нашёл глобальный минимум, сильно смещают среднее
значение.  Чем чаще оптимизатор будет промахиваться мимо глобального
минимума, тем сильнее отклонение.  Такое поведение оказывается весьма
удобным при сравнении различных алгоритмов.  Оно позволяет не только
оценить, насколько быстро оптимизатор способен добраться до дна
минимума, но и то, как часто он промахивается мимо глобального
минимума.

Рассмотрим подробнее случай функции $f_{11}$ из
таблицы~\ref{tbl:opt-results-jade-100d}.  Результат оптимизации с использованием исходного алгоритма адаптации и ГПСЧ MT19937 сильно (приблизительно на 7 порядков величины) отличается от
значений, полученных в остальных случаях.  Для проверки этого факта
оптимизация была запущена ещё раз с промежуточной выдачей результатов
усреднения после каждых 10 дополнительных прогонов.  Были получены
следующие данные: после 40 прогонов среднее значение и его
среднеквадратичное отклонение составили 2.0e-14 и (1.3e-14), а после
50 --- 1.5e-04 и (1.0e-03).  Иначе говоря, для последних 10 прогонов
оптимизатор не попал в глобальный минимум один или более раз, что и
обусловило полученный результат.  Удобным индикатором подобных
промахов является среднеквадратичное отклонение: когда промахов
нет, то оно оказывается сопоставимым или меньше величины среднего значения,
в противном случае оно будет значительно больше (на порядок величины или около того).
 Например, для функции $f_{12}$ в той же таблице большинство
значений оказалось на 9 порядков меньше, чем среднее значение для
JADE\texttt{++} ranlux48. Аналогичный анализ значений среднеквадратичного
отклонения подтверждает наличие промахов оптимизатора мимо глобального
минимума в этом случае.
% f11	gen500	2.0e-14 (1.3e-14) runs(40) at (-600,600)   100D MT wo PMCRADE
% f11	gen500	1.5e-04 (1.0e-03) runs(50) at (-600,600) 100D MT wo PMCRADE

\section{Выводы}
 
Был проведён анализ существующих алгоритмов оптимизации, выбрано
семейство алгоритмов, которые наилучшим образом подходят для решения
обратной задачи теории Ми. В этом семействе был выбран алгоритм
адаптивной дифференциальной эволюции, как обладающий наибольшей
производительностью.  Выполненная в рамках настоящей работы реализация
этого алгоритма позволяет эффективно использовать современные
процессоры с большим количеством параллельных потоков вычисления и
может выполняться на суперкомпьютерных кластерах.
Разработанное~\cite{JADE-web} программное обеспечение успешно проходит
набор стандартных тестов для алгоритмов оптимизации, для него было получено
свидетельство о государственной регистрации программы для
ЭВМ~№2014611568.
\clearpage